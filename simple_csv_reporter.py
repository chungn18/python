# test_drm_get_dbpath.py - FILE DUY NHáº¤T
import unittest
import csv
import json
import time
from datetime import datetime

class SubTestResult(unittest.TextTestResult):
    """TestResult vá»›i CSV reporting vÃ  terminal summary."""
    
    def __init__(self, stream, descriptions, verbosity):
        super().__init__(stream, descriptions, verbosity)
        
        # Statistics
        self.stats = {
            'total_main_tests': 0,      # Tá»•ng test cases
            'total_subtests': 0,        # Tá»•ng subtests
            'total_passed': 0,          # Tá»•ng passed (cáº£ test vÃ  subtest)
            'total_failed': 0,          # Tá»•ng failed
            'total_errors': 0,          # Tá»•ng errors
            'failed_tests': [],         # List test failed
            'error_tests': [],          # List test error
            'start_time': time.time()   # Thá»i gian báº¯t Ä‘áº§u
        }
        
        # Táº¡o CSV file
        self.csv_file = open('test_results.csv', 'w', newline='', encoding='utf-8')
        self.writer = csv.writer(self.csv_file)
        
        # Viáº¿t headers
        self.writer.writerow([
            'test_case_name', 'subtest_name', 'test_function',
            'args', 'return_value', 'final_result', 'timestamp'
        ])
    
    def startTest(self, test):
        super().startTest(test)
        self.stats['total_main_tests'] += 1
        if not hasattr(test, '_test_data'):
            test._test_data = {}
    
    def addSuccess(self, test):
        super().addSuccess(test)
        self.stats['total_passed'] += 1
        self._write_to_csv(test, '', 'PASSED')
    
    def addFailure(self, test, err):
        super().addFailure(test, err)
        self.stats['total_failed'] += 1
        self.stats['failed_tests'].append(test.id())
        self._write_to_csv(test, '', 'FAILED')
    
    def addError(self, test, err):
        super().addError(test, err)
        self.stats['total_errors'] += 1
        self.stats['error_tests'].append(test.id())
        self._write_to_csv(test, '', 'ERROR')
    
    def addSubTest(self, test, subtest, outcome):
        super().addSubTest(test, subtest, outcome)
        self.stats['total_subtests'] += 1
        
        # Láº¥y tÃªn subtest
        subtest_desc = getattr(subtest, '_subDescription', lambda: '')()
        
        # XÃ¡c Ä‘á»‹nh status
        if outcome is None:
            status = 'PASSED'
            self.stats['total_passed'] += 1
        else:
            if outcome[0] == self.FAILURE:
                status = 'FAILED'
                self.stats['total_failed'] += 1
            else:
                status = 'ERROR'
                self.stats['total_errors'] += 1
        
        # Ghi vÃ o CSV
        self._write_to_csv(test, subtest_desc, status)
    
    def _write_to_csv(self, test, subtest_name, status):
        """Ghi káº¿t quáº£ vÃ o CSV."""
        data = getattr(test, '_test_data', {})
        
        self.writer.writerow([
            test.id(),                              # test_case_name
            subtest_name,                           # subtest_name
            test._testMethodName,                   # test_function
            json.dumps(data.get('args', [])),       # args
            json.dumps(data.get('return_value', '')),  # return_value
            status,                                 # final_result
            datetime.now().isoformat()              # timestamp
        ])
        self.csv_file.flush()
    
    def print_summary(self):
        """In summary ra terminal."""
        end_time = time.time()
        duration = end_time - self.stats['start_time']
        
        # TÃ­nh tá»•ng sá»‘ tests Ä‘Ã£ cháº¡y
        total_tests_run = (self.stats['total_main_tests'] + 
                          self.stats['total_subtests'])
        
        # TÃ­nh success rate
        total_successful = self.stats['total_passed']
        success_rate = (total_successful / total_tests_run * 100) if total_tests_run > 0 else 0
        
        print("\n" + "="*60)
        print("ğŸ“Š TEST EXECUTION SUMMARY")
        print("="*60)
        
        # In statistics
        print(f"\nğŸ“ˆ STATISTICS:")
        print(f"   Total Test Cases:    {self.stats['total_main_tests']}")
        print(f"   Total Subtests:      {self.stats['total_subtests']}")
        print(f"   Total Tests Run:     {total_tests_run}")
        print(f"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"   âœ… Passed:           {self.stats['total_passed']}")
        print(f"   âŒ Failed:           {self.stats['total_failed']}")
        print(f"   âš ï¸  Errors:           {self.stats['total_errors']}")
        print(f"   Success Rate:        {success_rate:.1f}%")
        print(f"   Execution Time:      {duration:.2f} seconds")
        
        # In failed tests
        if self.stats['failed_tests']:
            print(f"\nâŒ FAILED TESTS ({len(self.stats['failed_tests'])}):")
            for test_name in self.stats['failed_tests']:
                print(f"   â€¢ {test_name}")
        
        # In error tests
        if self.stats['error_tests']:
            print(f"\nâš ï¸  ERROR TESTS ({len(self.stats['error_tests'])}):")
            for test_name in self.stats['error_tests']:
                print(f"   â€¢ {test_name}")
        
        # In file info
        print(f"\nğŸ’¾ OUTPUT FILES:")
        print(f"   CSV Results:        test_results.csv")
        
        print("\n" + "="*60)
    
    def stopTestRun(self):
        """Override Ä‘á»ƒ in summary."""
        super().stopTestRun()
        self.print_summary()
        self.csv_file.close()